import pandas as pd
import os
import logging
from typing import Dict, List, Optional
from pathlib import Path
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

logger = logging.getLogger(__name__)

def create_session_with_retry() -> requests.Session:
    """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã®HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
    session = requests.Session()
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session

def validate_api_config(api: Dict) -> bool:
    """APIè¨­å®šã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
    required_fields = ["name", "url", "filename"]
    for field in required_fields:
        if not api.get(field):
            logger.error(f"APIè¨­å®šã«å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ '{field}' ãŒã‚ã‚Šã¾ã›ã‚“: {api}")
            return False
    return True

def fetch_from_api(url: str, output_path: str, name: str) -> Optional[pd.DataFrame]:
    """APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦CSVã«ä¿å­˜"""
    try:
        session = create_session_with_retry()
        logger.info(f"ğŸŒ {name} ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­ï¼ˆAPIã‚¢ã‚¯ã‚»ã‚¹ï¼‰...")
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã§APIã‚¢ã‚¯ã‚»ã‚¹
        response = session.get(url, timeout=60)
        response.raise_for_status()
        
        # CSVãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦èª­ã¿è¾¼ã¿
        from io import StringIO
        df = pd.read_csv(StringIO(response.text), low_memory=False)
        
        if df.empty:
            logger.warning(f"{name}: ç©ºã®ãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã¾ã—ãŸ")
            return None
            
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        df.to_csv(output_path, index=False, encoding="utf-8-sig")
        logger.info(f"âœ… ä¿å­˜å®Œäº†: {output_path} ({len(df)}è¡Œ)")
        
        return df
        
    except requests.exceptions.Timeout:
        logger.error(f"âŒ {name}: APIã‚¢ã‚¯ã‚»ã‚¹ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
        return None
    except requests.exceptions.ConnectionError:
        logger.error(f"âŒ {name}: APIæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
        return None
    except requests.exceptions.HTTPError as e:
        logger.error(f"âŒ {name}: HTTPã‚¨ãƒ©ãƒ¼ {e.response.status_code}")
        return None
    except pd.errors.EmptyDataError:
        logger.error(f"âŒ {name}: CSVãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
        return None
    except Exception as e:
        logger.error(f"âŒ {name}: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def load_from_csv(output_path: str, name: str) -> Optional[pd.DataFrame]:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    try:
        if not Path(output_path).exists():
            logger.error(f"âŒ {name}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {output_path}")
            return None
            
        logger.info(f"ğŸ§ª [TEST] {name} ã‚’CSVã‹ã‚‰èª­ã¿è¾¼ã¿ä¸­...")
        df = pd.read_csv(output_path, low_memory=False)
        
        if df.empty:
            logger.warning(f"âš ï¸ {name}: CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
            return None
            
        logger.info(f"âœ… èª­ã¿è¾¼ã¿å®Œäº†: {name} ({len(df)}è¡Œ)")
        return df
        
    except pd.errors.EmptyDataError:
        logger.error(f"âŒ {name}: CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã¾ãŸã¯ä¸æ­£ã§ã™")
        return None
    except Exception as e:
        logger.error(f"âŒ {name}: CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def fetch_bis_datasets(api_list: List[Dict], output_dir: str, test_mode: bool = False) -> Dict[str, pd.DataFrame]:
    """
    BISãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦è¾æ›¸å½¢å¼ã§è¿”ã™ã€‚
    ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã¯ã€æ—¢å­˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ã€‚

    Parameters:
    - api_list: List[Dict] â† YAMLã§å®šç¾©ã•ã‚ŒãŸBIS APIè¨­å®š
    - output_dir: ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿å…ˆãƒ•ã‚©ãƒ«ãƒ€
    - test_mode: Trueãªã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼ˆAPIã‚¢ã‚¯ã‚»ã‚¹ãªã—ï¼‰

    Returns:
    - Dict[str, pd.DataFrame]: {name: DataFrame}
    
    Raises:
    - ValueError: APIè¨­å®šãŒä¸æ­£ãªå ´åˆ
    - OSError: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã«å¤±æ•—ã—ãŸå ´åˆ
    """
    if not api_list:
        raise ValueError("APIè¨­å®šãƒªã‚¹ãƒˆãŒç©ºã§ã™")
        
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    try:
        Path(output_dir).mkdir(parents=True, exist_ok=True)
    except OSError as e:
        logger.error(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã«å¤±æ•—: {output_dir}")
        raise
    
    df_dict = {}
    successful_downloads = 0
    
    for api in api_list:
        # APIè¨­å®šæ¤œè¨¼
        if not validate_api_config(api):
            continue
            
        name = api["name"]
        url = api["url"]
        filename = api["filename"]
        output_path = Path(output_dir) / filename
        
        try:
            if test_mode:
                df = load_from_csv(str(output_path), name)
            else:
                df = fetch_from_api(url, str(output_path), name)
            
            if df is not None:
                df_dict[name] = df
                successful_downloads += 1
            else:
                logger.warning(f"âš ï¸ {name}: ãƒ‡ãƒ¼ã‚¿ã®å–å¾—/èª­ã¿è¾¼ã¿ã«å¤±æ•—")
                
        except Exception as e:
            logger.error(f"âŒ {name}: å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            continue
    
    logger.info(f"ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {successful_downloads}/{len(api_list)} æˆåŠŸ")
    
    if not df_dict:
        raise ValueError("ã™ã¹ã¦ã®BISãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    return df_dict


def validate_bis_dataframe(df: pd.DataFrame, name: str) -> bool:
    """
    BISãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çš„ãªå¦¥å½“æ€§ã‚’æ¤œè¨¼
    
    Parameters:
    - df: æ¤œè¨¼å¯¾è±¡ã®DataFrame
    - name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
    
    Returns:
    - bool: å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯çµæœ
    """
    try:
        # åŸºæœ¬ãƒã‚§ãƒƒã‚¯
        if df.empty:
            logger.warning(f"{name}: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return False
            
        # å¿…è¦æœ€å°é™ã®åˆ—æ•°ãƒã‚§ãƒƒã‚¯
        if len(df.columns) < 3:
            logger.warning(f"{name}: åˆ—æ•°ãŒå°‘ãªã™ãã¾ã™ ({len(df.columns)}åˆ—)")
            return False
            
        # ä¸€èˆ¬çš„ãªBISãƒ‡ãƒ¼ã‚¿ã®å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
        expected_columns = ["TIME_PERIOD", "OBS_VALUE"]
        missing_columns = [col for col in expected_columns if col not in df.columns]
        
        if missing_columns:
            logger.warning(f"{name}: å¿…é ˆåˆ—ãŒä¸è¶³: {missing_columns}")
            return False
            
        # ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯
        if "OBS_VALUE" in df.columns:
            numeric_count = pd.to_numeric(df["OBS_VALUE"], errors="coerce").notna().sum()
            if numeric_count == 0:
                logger.warning(f"{name}: OBS_VALUEåˆ—ã«æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return False
                
        logger.info(f"âœ… {name}: ãƒ‡ãƒ¼ã‚¿å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯é€šé ({len(df)}è¡Œ, {len(df.columns)}åˆ—)")
        return True
        
    except Exception as e:
        logger.error(f"âŒ {name}: å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return False
